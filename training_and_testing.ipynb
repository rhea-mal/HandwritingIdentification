{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import label, regionprops\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Load the image in grayscale mode\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply a 3x3 median filter for noise removal\n",
    "    denoised_image = cv2.medianBlur(image, 3)\n",
    "\n",
    "    # Apply Otsu's thresholding for binarization\n",
    "    _, binarized_image = cv2.threshold(denoised_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    return binarized_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, cropx, cropy):\n",
    "    y, x = img.shape\n",
    "    startx = x // 2 - cropx // 2\n",
    "    starty = y // 2 - cropy // 2\n",
    "    return img[starty:starty + cropy, startx:startx + cropx]\n",
    "\n",
    "def calculate_pixel_percentages(img, m=100):\n",
    "    cropped_img = crop_center(img, m, m)\n",
    "    black_pixels = np.sum(cropped_img < 128)\n",
    "    white_pixels = np.sum(cropped_img >= 128)\n",
    "    total_pixels = m * m\n",
    "    percentage_black_pixels = (black_pixels / total_pixels) * 100\n",
    "    percentage_white_pixels = (white_pixels / total_pixels) * 100\n",
    "\n",
    "    return percentage_black_pixels, percentage_white_pixels\n",
    "def calculate_line_irregularity(binary_img):\n",
    "    # Ensure binary_img is of type uint8\n",
    "    binary_img = binary_img.astype(np.uint8) * 255\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated_img = cv2.dilate(binary_img, kernel, iterations=1)\n",
    "\n",
    "    # Calculate projection profile as a sum of pixels along each row\n",
    "    projection = np.sum(dilated_img, axis=1)\n",
    "    \n",
    "    # Make projection 2-D for processing with label and regionprops\n",
    "    projection_2d = np.expand_dims(projection, axis=1)\n",
    "\n",
    "    # Basic peak detection\n",
    "    peaks = projection_2d > np.mean(projection)\n",
    "    labeled_peaks, num_features = label(peaks, return_num=True)\n",
    "    props = regionprops(labeled_peaks)\n",
    "\n",
    "    # Calculate the standard deviation of the line heights\n",
    "    heights = [prop.bbox[2] - prop.bbox[0] for prop in props]  # Height is max_row - min_row\n",
    "    line_irregularity = np.std(heights) if heights else 0\n",
    "\n",
    "    return line_irregularity\n",
    "\n",
    "def extract_features(image):\n",
    "    # Binary image for pixel percentage calculation\n",
    "    _, binary_img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    hog_features, _ = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                          cells_per_block=(1, 1), visualize=True, feature_vector=True)\n",
    "    \n",
    "    numPoints = 24\n",
    "    radius = 8\n",
    "       # Local Binary Pattern\n",
    "    lbp = local_binary_pattern(binary_img, numPoints, radius, method=\"uniform\")\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, numPoints + 3), range=(0, numPoints + 2))\n",
    "    lbp_hist = lbp_hist.astype(\"float\")\n",
    "    lbp_hist /= (lbp_hist.sum() + 1e-7)  # Normalize\n",
    "\n",
    "        \n",
    "        # Combine HOG and LBP embeddings\n",
    "    embedding = np.append(hog_features, lbp_hist)\n",
    "\n",
    "\n",
    "    skeleton = skeletonize(binary_img > 0)\n",
    "    endpoints = np.array((skeleton & np.roll(~skeleton, shift=1, axis=0)) |\n",
    "                         (skeleton & np.roll(~skeleton, shift=-1, axis=0)) |\n",
    "                         (skeleton & np.roll(~skeleton, shift=1, axis=1)) |\n",
    "                         (skeleton & np.roll(~skeleton, shift=-1, axis=1)))\n",
    "    num_endpoints = np.sum(endpoints)\n",
    "\n",
    "    dist_transform = cv2.distanceTransform(binary_img, cv2.DIST_L2, 5)\n",
    "    avg_thickness = np.mean(dist_transform)\n",
    "\n",
    "    y, x = np.nonzero(sobel)\n",
    "    angles = np.arctan2(sobely[y, x], sobelx[y, x])\n",
    "    angle_diff = np.diff(angles)\n",
    "    avg_curvature = np.mean(np.abs(angle_diff))\n",
    "\n",
    "    percentage_black_pixels, percentage_white_pixels = calculate_pixel_percentages(binary_img, m=100)\n",
    "    line_irregularity = calculate_line_irregularity(binary_img)\n",
    "\n",
    "    avg_canny = np.mean(edges)\n",
    "    avg_sobel = np.mean(sobel)\n",
    "    avg_hog = np.mean(hog_features)\n",
    "\n",
    "    return (avg_canny, avg_sobel, avg_hog, num_endpoints, avg_thickness, avg_curvature,\n",
    "            percentage_black_pixels, percentage_white_pixels, line_irregularity, embedding.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student_features.csv')\n",
    "df.head()\n",
    "\n",
    "filtered_df = df[df['Image Name'].str.contains('pLND')]\n",
    "\n",
    "filtered_df.head()\n",
    "\n",
    "# List of student IDs to keep\n",
    "students_to_keep = ['student_4', 'student_23', 'student_22', 'student_20', 'student_34']\n",
    "\n",
    "# Filter rows based on the 'Student' column using isin() and boolean indexing\n",
    "df = filtered_df[filtered_df['Student'].isin(students_to_keep)]\n",
    "# MOST VARYING STUDENTS: STUDENT_22 STUDENT_4 STUDENT_20 STUDENT_23 STUDENT_34\n",
    "\n",
    "df.to_csv('filtered_students.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 2.4120 - accuracy: 0.5556 - val_loss: 2.5478 - val_accuracy: 0.3333\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.4328 - accuracy: 0.4444 - val_loss: 2.5190 - val_accuracy: 0.3333\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3958 - accuracy: 0.3333 - val_loss: 2.4857 - val_accuracy: 0.3333\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.7058 - accuracy: 0.1111 - val_loss: 2.4488 - val_accuracy: 0.3333\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.4350 - accuracy: 0.4444 - val_loss: 2.4140 - val_accuracy: 0.3333\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4720 - accuracy: 0.4444 - val_loss: 2.3808 - val_accuracy: 0.3333\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3473 - accuracy: 0.4444 - val_loss: 2.3513 - val_accuracy: 0.3333\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3950 - accuracy: 0.4444 - val_loss: 2.3224 - val_accuracy: 0.3333\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2962 - accuracy: 0.3333 - val_loss: 2.2948 - val_accuracy: 0.3333\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2095 - accuracy: 0.6667 - val_loss: 2.2687 - val_accuracy: 0.3333\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1830 - accuracy: 0.6667 - val_loss: 2.2430 - val_accuracy: 0.3333\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2473 - accuracy: 0.3333 - val_loss: 2.2184 - val_accuracy: 0.3333\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1849 - accuracy: 0.3333 - val_loss: 2.1964 - val_accuracy: 0.3333\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.1981 - accuracy: 0.4444 - val_loss: 2.1744 - val_accuracy: 0.3333\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2355 - accuracy: 0.6667 - val_loss: 2.1541 - val_accuracy: 0.3333\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.0058 - accuracy: 0.4444 - val_loss: 2.1351 - val_accuracy: 0.3333\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1785 - accuracy: 0.5556 - val_loss: 2.1178 - val_accuracy: 0.3333\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9924 - accuracy: 0.6667 - val_loss: 2.0996 - val_accuracy: 0.3333\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0200 - accuracy: 0.6667 - val_loss: 2.0805 - val_accuracy: 0.3333\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3193 - accuracy: 0.3333 - val_loss: 2.0626 - val_accuracy: 0.3333\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2104 - accuracy: 0.5556 - val_loss: 2.0461 - val_accuracy: 0.6667\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0706 - accuracy: 0.4444 - val_loss: 2.0297 - val_accuracy: 0.6667\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.0346 - accuracy: 0.4444 - val_loss: 2.0134 - val_accuracy: 0.6667\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0168 - accuracy: 0.6667 - val_loss: 1.9981 - val_accuracy: 0.6667\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9397 - accuracy: 0.4444 - val_loss: 1.9833 - val_accuracy: 0.6667\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.8597 - accuracy: 0.7778 - val_loss: 1.9693 - val_accuracy: 0.6667\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9077 - accuracy: 0.6667 - val_loss: 1.9563 - val_accuracy: 0.6667\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.0346 - accuracy: 0.6667 - val_loss: 1.9436 - val_accuracy: 0.6667\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8354 - accuracy: 0.7778 - val_loss: 1.9318 - val_accuracy: 0.6667\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7575 - accuracy: 0.6667 - val_loss: 1.9212 - val_accuracy: 0.6667\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7647 - accuracy: 0.5556 - val_loss: 1.9109 - val_accuracy: 0.6667\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.8779 - accuracy: 0.7778 - val_loss: 1.9011 - val_accuracy: 0.6667\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7881 - accuracy: 0.7778 - val_loss: 1.8914 - val_accuracy: 0.6667\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7957 - accuracy: 0.4444 - val_loss: 1.8813 - val_accuracy: 0.6667\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9088 - accuracy: 0.6667 - val_loss: 1.8702 - val_accuracy: 0.6667\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7760 - accuracy: 0.5556 - val_loss: 1.8594 - val_accuracy: 0.6667\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7452 - accuracy: 0.7778 - val_loss: 1.8492 - val_accuracy: 0.6667\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8816 - accuracy: 0.5556 - val_loss: 1.8385 - val_accuracy: 0.6667\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6712 - accuracy: 1.0000 - val_loss: 1.8290 - val_accuracy: 0.6667\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8607 - accuracy: 0.5556 - val_loss: 1.8200 - val_accuracy: 0.6667\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6214 - accuracy: 0.7778 - val_loss: 1.8120 - val_accuracy: 0.6667\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6804 - accuracy: 0.8889 - val_loss: 1.8043 - val_accuracy: 0.6667\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7237 - accuracy: 0.7778 - val_loss: 1.7964 - val_accuracy: 0.6667\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6832 - accuracy: 0.5556 - val_loss: 1.7891 - val_accuracy: 0.6667\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5766 - accuracy: 0.7778 - val_loss: 1.7831 - val_accuracy: 0.6667\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6958 - accuracy: 0.6667 - val_loss: 1.7781 - val_accuracy: 0.6667\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5836 - accuracy: 0.8889 - val_loss: 1.7736 - val_accuracy: 0.6667\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6198 - accuracy: 0.7778 - val_loss: 1.7691 - val_accuracy: 0.6667\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5520 - accuracy: 0.5556 - val_loss: 1.7652 - val_accuracy: 0.6667\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9793 - accuracy: 0.6667 - val_loss: 1.7615 - val_accuracy: 0.6667\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6606 - accuracy: 0.6667 - val_loss: 1.7586 - val_accuracy: 0.6667\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4546 - accuracy: 0.8889 - val_loss: 1.7562 - val_accuracy: 0.6667\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5478 - accuracy: 0.7778 - val_loss: 1.7542 - val_accuracy: 0.6667\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4830 - accuracy: 0.8889 - val_loss: 1.7512 - val_accuracy: 0.6667\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5480 - accuracy: 0.7778 - val_loss: 1.7474 - val_accuracy: 0.6667\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6336 - accuracy: 0.7778 - val_loss: 1.7443 - val_accuracy: 0.6667\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5173 - accuracy: 0.6667 - val_loss: 1.7410 - val_accuracy: 0.6667\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5241 - accuracy: 0.7778 - val_loss: 1.7377 - val_accuracy: 0.6667\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5805 - accuracy: 0.7778 - val_loss: 1.7340 - val_accuracy: 0.6667\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3313 - accuracy: 0.8889 - val_loss: 1.7307 - val_accuracy: 0.6667\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4058 - accuracy: 0.8889 - val_loss: 1.7273 - val_accuracy: 0.6667\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6893 - accuracy: 0.5556 - val_loss: 1.7237 - val_accuracy: 0.6667\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4635 - accuracy: 0.7778 - val_loss: 1.7208 - val_accuracy: 0.6667\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5036 - accuracy: 0.6667 - val_loss: 1.7180 - val_accuracy: 0.6667\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3530 - accuracy: 0.8889 - val_loss: 1.7153 - val_accuracy: 0.6667\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2821 - accuracy: 1.0000 - val_loss: 1.7136 - val_accuracy: 0.6667\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4543 - accuracy: 0.7778 - val_loss: 1.7130 - val_accuracy: 0.6667\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4396 - accuracy: 1.0000 - val_loss: 1.7123 - val_accuracy: 0.6667\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4082 - accuracy: 0.8889 - val_loss: 1.7106 - val_accuracy: 0.6667\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4435 - accuracy: 0.7778 - val_loss: 1.7085 - val_accuracy: 0.6667\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3895 - accuracy: 0.7778 - val_loss: 1.7069 - val_accuracy: 0.6667\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4736 - accuracy: 0.8889 - val_loss: 1.7061 - val_accuracy: 0.6667\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2788 - accuracy: 0.8889 - val_loss: 1.7071 - val_accuracy: 0.6667\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3885 - accuracy: 0.7778 - val_loss: 1.7075 - val_accuracy: 0.6667\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4034 - accuracy: 0.8889 - val_loss: 1.7085 - val_accuracy: 0.6667\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3015 - accuracy: 0.8889 - val_loss: 1.7096 - val_accuracy: 0.6667\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3258 - accuracy: 0.8889 - val_loss: 1.7105 - val_accuracy: 0.6667\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2007 - accuracy: 0.7778 - val_loss: 1.7126 - val_accuracy: 0.6667\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2007 - accuracy: 1.0000 - val_loss: 1.7153 - val_accuracy: 0.6667\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2076 - accuracy: 0.8889 - val_loss: 1.7176 - val_accuracy: 0.6667\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4279 - accuracy: 0.6667 - val_loss: 1.7194 - val_accuracy: 0.6667\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3831 - accuracy: 0.7778 - val_loss: 1.7208 - val_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9787 - accuracy: 0.0000e+00\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Student' is the label and the rest are features\n",
    "X = df.drop(['Student', 'Image Name'], axis=1)\n",
    "y = df['Student']\n",
    "\n",
    "# Encode the categorical labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build a neural network model with dropout and L2 regularization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(set(y_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train, epochs=2000, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_author(features, model, scaler, label_encoder):\n",
    "    # Convert the features tuple to a 2D array and scale it\n",
    "    features_array = np.array([features])\n",
    "    features_scaled = scaler.transform(features_array)\n",
    "    \n",
    "    # Use the model to predict probabilities\n",
    "    probabilities = model.predict(features_scaled)[0]\n",
    "    \n",
    "    # Get the indices of the top 10 probabilities\n",
    "    top_indices = np.argsort(probabilities)[-5:][::-1]\n",
    "    \n",
    "    # Get the corresponding student labels and probabilities\n",
    "    top_students = label_encoder.inverse_transform(top_indices)\n",
    "    top_probabilities = probabilities[top_indices]\n",
    "    \n",
    "    # Format and return the results\n",
    "    return [(student, prob) for student, prob in zip(top_students, top_probabilities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_20\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_20 has a 47.08% chance of being the author\n",
      "student_22 has a 18.18% chance of being the author\n",
      "student_23 has a 15.77% chance of being the author\n",
      "student_34 has a 10.29% chance of being the author\n",
      "student_4 has a 8.68% chance of being the author\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_20\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_20 has a 54.58% chance of being the author\n",
      "student_23 has a 19.96% chance of being the author\n",
      "student_22 has a 12.33% chance of being the author\n",
      "student_34 has a 7.90% chance of being the author\n",
      "student_4 has a 5.23% chance of being the author\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_20\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_20 has a 49.97% chance of being the author\n",
      "student_22 has a 17.56% chance of being the author\n",
      "student_23 has a 15.65% chance of being the author\n",
      "student_34 has a 9.28% chance of being the author\n",
      "student_4 has a 7.55% chance of being the author\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_20\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_20 has a 53.76% chance of being the author\n",
      "student_23 has a 15.74% chance of being the author\n",
      "student_34 has a 14.09% chance of being the author\n",
      "student_22 has a 10.59% chance of being the author\n",
      "student_4 has a 5.82% chance of being the author\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_20\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_20 has a 59.36% chance of being the author\n",
      "student_23 has a 21.85% chance of being the author\n",
      "student_22 has a 10.85% chance of being the author\n",
      "student_34 has a 5.29% chance of being the author\n",
      "student_4 has a 2.65% chance of being the author\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_20\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_20 has a 56.55% chance of being the author\n",
      "student_23 has a 20.27% chance of being the author\n",
      "student_22 has a 9.53% chance of being the author\n",
      "student_34 has a 9.49% chance of being the author\n",
      "student_4 has a 4.15% chance of being the author\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_22\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_22 has a 38.90% chance of being the author\n",
      "student_4 has a 32.34% chance of being the author\n",
      "student_20 has a 13.25% chance of being the author\n",
      "student_23 has a 10.49% chance of being the author\n",
      "student_34 has a 5.01% chance of being the author\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_22\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 0.8, Rank: 2\n",
      "student_4 has a 41.82% chance of being the author\n",
      "student_22 has a 40.01% chance of being the author\n",
      "student_20 has a 7.41% chance of being the author\n",
      "student_23 has a 6.72% chance of being the author\n",
      "student_34 has a 4.03% chance of being the author\n",
      "0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_22\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 0.8, Rank: 2\n",
      "student_4 has a 64.13% chance of being the author\n",
      "student_22 has a 30.50% chance of being the author\n",
      "student_20 has a 2.08% chance of being the author\n",
      "student_23 has a 1.69% chance of being the author\n",
      "student_34 has a 1.59% chance of being the author\n",
      "0.9555555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_22\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 0.8, Rank: 2\n",
      "student_4 has a 57.95% chance of being the author\n",
      "student_22 has a 35.18% chance of being the author\n",
      "student_20 has a 2.66% chance of being the author\n",
      "student_23 has a 2.28% chance of being the author\n",
      "student_34 has a 1.93% chance of being the author\n",
      "0.9400000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_22\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_22 has a 44.67% chance of being the author\n",
      "student_4 has a 37.52% chance of being the author\n",
      "student_20 has a 7.00% chance of being the author\n",
      "student_23 has a 6.82% chance of being the author\n",
      "student_34 has a 4.00% chance of being the author\n",
      "0.9454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_22\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 0.8, Rank: 2\n",
      "student_4 has a 41.10% chance of being the author\n",
      "student_22 has a 39.51% chance of being the author\n",
      "student_20 has a 7.13% chance of being the author\n",
      "student_23 has a 7.12% chance of being the author\n",
      "student_34 has a 5.14% chance of being the author\n",
      "0.9333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_23\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 0.8, Rank: 2\n",
      "student_20 has a 65.06% chance of being the author\n",
      "student_23 has a 14.16% chance of being the author\n",
      "student_22 has a 10.18% chance of being the author\n",
      "student_34 has a 6.27% chance of being the author\n",
      "student_4 has a 4.34% chance of being the author\n",
      "0.9230769230769232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_23\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 0.8, Rank: 2\n",
      "student_22 has a 50.75% chance of being the author\n",
      "student_23 has a 19.37% chance of being the author\n",
      "student_20 has a 16.78% chance of being the author\n",
      "student_4 has a 10.03% chance of being the author\n",
      "student_34 has a 3.07% chance of being the author\n",
      "0.9142857142857145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_23\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 0.6, Rank: 3\n",
      "student_22 has a 36.17% chance of being the author\n",
      "student_20 has a 31.01% chance of being the author\n",
      "student_23 has a 24.58% chance of being the author\n",
      "student_4 has a 5.20% chance of being the author\n",
      "student_34 has a 3.04% chance of being the author\n",
      "0.8933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_23\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 0.6, Rank: 3\n",
      "student_22 has a 32.38% chance of being the author\n",
      "student_20 has a 28.93% chance of being the author\n",
      "student_23 has a 21.83% chance of being the author\n",
      "student_4 has a 10.07% chance of being the author\n",
      "student_34 has a 6.79% chance of being the author\n",
      "0.8750000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_23\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 0.6, Rank: 3\n",
      "student_22 has a 39.28% chance of being the author\n",
      "student_20 has a 24.74% chance of being the author\n",
      "student_23 has a 23.86% chance of being the author\n",
      "student_4 has a 8.33% chance of being the author\n",
      "student_34 has a 3.79% chance of being the author\n",
      "0.8588235294117648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_23\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 0.8, Rank: 2\n",
      "student_20 has a 37.40% chance of being the author\n",
      "student_23 has a 30.62% chance of being the author\n",
      "student_22 has a 21.52% chance of being the author\n",
      "student_4 has a 5.39% chance of being the author\n",
      "student_34 has a 5.07% chance of being the author\n",
      "0.8555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_34\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_34 has a 95.43% chance of being the author\n",
      "student_20 has a 3.16% chance of being the author\n",
      "student_23 has a 0.79% chance of being the author\n",
      "student_22 has a 0.43% chance of being the author\n",
      "student_4 has a 0.19% chance of being the author\n",
      "0.8631578947368422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_34\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_34 has a 93.10% chance of being the author\n",
      "student_20 has a 4.53% chance of being the author\n",
      "student_23 has a 1.29% chance of being the author\n",
      "student_22 has a 0.70% chance of being the author\n",
      "student_4 has a 0.37% chance of being the author\n",
      "0.8700000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_34\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_34 has a 89.22% chance of being the author\n",
      "student_20 has a 6.92% chance of being the author\n",
      "student_23 has a 2.03% chance of being the author\n",
      "student_22 has a 1.23% chance of being the author\n",
      "student_4 has a 0.60% chance of being the author\n",
      "0.8761904761904763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_34\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_34 has a 88.82% chance of being the author\n",
      "student_20 has a 7.43% chance of being the author\n",
      "student_23 has a 2.05% chance of being the author\n",
      "student_22 has a 1.12% chance of being the author\n",
      "student_4 has a 0.58% chance of being the author\n",
      "0.881818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_34\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_34 has a 92.91% chance of being the author\n",
      "student_20 has a 5.17% chance of being the author\n",
      "student_23 has a 1.16% chance of being the author\n",
      "student_22 has a 0.51% chance of being the author\n",
      "student_4 has a 0.25% chance of being the author\n",
      "0.8869565217391305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_34\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_34 has a 88.58% chance of being the author\n",
      "student_20 has a 7.38% chance of being the author\n",
      "student_23 has a 2.07% chance of being the author\n",
      "student_22 has a 1.37% chance of being the author\n",
      "student_4 has a 0.60% chance of being the author\n",
      "0.8916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_4\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_4 has a 79.15% chance of being the author\n",
      "student_22 has a 18.96% chance of being the author\n",
      "student_20 has a 0.80% chance of being the author\n",
      "student_23 has a 0.79% chance of being the author\n",
      "student_34 has a 0.30% chance of being the author\n",
      "0.8960000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_4\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_4 has a 80.73% chance of being the author\n",
      "student_22 has a 18.71% chance of being the author\n",
      "student_23 has a 0.23% chance of being the author\n",
      "student_20 has a 0.18% chance of being the author\n",
      "student_34 has a 0.15% chance of being the author\n",
      "0.9000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_4\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_4 has a 83.63% chance of being the author\n",
      "student_22 has a 15.54% chance of being the author\n",
      "student_23 has a 0.33% chance of being the author\n",
      "student_20 has a 0.26% chance of being the author\n",
      "student_34 has a 0.24% chance of being the author\n",
      "0.9037037037037038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_4\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_4 has a 87.89% chance of being the author\n",
      "student_22 has a 11.77% chance of being the author\n",
      "student_23 has a 0.14% chance of being the author\n",
      "student_20 has a 0.11% chance of being the author\n",
      "student_34 has a 0.09% chance of being the author\n",
      "0.9071428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_4\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Points awarded: 1.0, Rank: 1\n",
      "student_4 has a 80.80% chance of being the author\n",
      "student_22 has a 17.07% chance of being the author\n",
      "student_23 has a 0.83% chance of being the author\n",
      "student_20 has a 0.74% chance of being the author\n",
      "student_34 has a 0.56% chance of being the author\n",
      "0.9103448275862069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE AUTHOR IS:  student_4\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Points awarded: 0.8, Rank: 2\n",
      "student_22 has a 48.21% chance of being the author\n",
      "student_4 has a 47.03% chance of being the author\n",
      "student_23 has a 1.94% chance of being the author\n",
      "student_20 has a 1.84% chance of being the author\n",
      "student_34 has a 0.98% chance of being the author\n",
      "0.9066666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def predict_and_score(features, true_author, model, scaler, label_encoder):\n",
    "    # Predict the author based on the features\n",
    "    predictions = predict_author(features, model, scaler, label_encoder)\n",
    "    predicted_labels, probabilities = zip(*predictions)\n",
    "\n",
    "    # Find the rank of the true author in the predictions\n",
    "    if true_author in predicted_labels:\n",
    "        rank = predicted_labels.index(true_author) + 1  # Get the rank (1-based indexing)\n",
    "    else:\n",
    "        rank = None  # Not in the top 10\n",
    "\n",
    "    points = (6 - rank) / 5  # Score equivalent to the placement (1st place = 1.0, 2nd place = 0.9, etc.)\n",
    "\n",
    "    return points, rank, predictions\n",
    "\n",
    "directory = 'test_images'\n",
    "\n",
    "total_accuracy = 0.0\n",
    "accuracy_score = 0.0\n",
    "count = 1\n",
    "# Loop through each folder in the directory\n",
    "for folder_name in os.listdir(directory):\n",
    "    true_author = folder_name\n",
    "    folder_path = os.path.join(directory, folder_name)\n",
    "    # Check if the item in the directory is a folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        for filename in os.listdir(folder_path):\n",
    "            image_path = 'test_images/' + true_author + '/' + filename\n",
    "            image = preprocess_image(image_path)\n",
    "            features_tuple = extract_features(image)\n",
    "            print(\"TRUE AUTHOR IS: \", true_author)\n",
    "            points, rank, predictions = predict_and_score(features_tuple, true_author, model, scaler, label_encoder)\n",
    "            print(f\"Points awarded: {points}, Rank: {rank}\")\n",
    "            for student, probability in predictions:\n",
    "                print(f\"{student} has a {probability * 100:.2f}% chance of being the author\")\n",
    "            total_accuracy += points\n",
    "            accuracy_score = total_accuracy / count\n",
    "            count += 1\n",
    "            print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in folder \"student_20\":\n",
      "w0020_s02_pLND_r01.png\n",
      "w0020_s02_pLND_r02.png\n",
      "w0020_s02_pLND_r03.png\n",
      "w0020_s03_pLND_r01.png\n",
      "w0020_s03_pLND_r02.png\n",
      "w0020_s03_pLND_r03.png\n",
      "Files in folder \"student_22\":\n",
      "w0022_s02_pLND_r01.png\n",
      "w0022_s02_pLND_r02.png\n",
      "w0022_s02_pLND_r03.png\n",
      "w0022_s03_pLND_r01.png\n",
      "w0022_s03_pLND_r02.png\n",
      "w0022_s03_pLND_r03.png\n",
      "Files in folder \"student_23\":\n",
      "w0023_s02_pLND_r01.png\n",
      "w0023_s02_pLND_r02.png\n",
      "w0023_s02_pLND_r03.png\n",
      "w0023_s03_pLND_r01.png\n",
      "w0023_s03_pLND_r02.png\n",
      "w0023_s03_pLND_r03.png\n",
      "Files in folder \"student_34\":\n",
      "w0034_s02_pLND_r01.png\n",
      "w0034_s02_pLND_r02.png\n",
      "w0034_s02_pLND_r03.png\n",
      "w0034_s03_pLND_r01.png\n",
      "w0034_s03_pLND_r02.png\n",
      "w0034_s03_pLND_r03.png\n",
      "Files in folder \"student_4\":\n",
      "w0004_s02_pLND_r01.png\n",
      "w0004_s02_pLND_r02.png\n",
      "w0004_s02_pLND_r03.png\n",
      "w0004_s03_pLND_r01.png\n",
      "w0004_s03_pLND_r02.png\n",
      "w0004_s03_pLND_r03.png\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "student_30 has a 32.28% chance of being the author\n",
      "student_16 has a 20.07% chance of being the author\n",
      "student_33 has a 13.08% chance of being the author\n",
      "student_34 has a 7.79% chance of being the author\n",
      "student_35 has a 6.66% chance of being the author\n",
      "student_25 has a 3.39% chance of being the author\n",
      "student_13 has a 3.03% chance of being the author\n",
      "student_18 has a 2.26% chance of being the author\n",
      "student_31 has a 1.98% chance of being the author\n",
      "student_2 has a 1.94% chance of being the author\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preprocessed_image = preprocess_image('student_30.png')\n",
    "features_tuple = extract_features(preprocessed_image)\n",
    "\n",
    "\n",
    "# Predict the author based on the features\n",
    "author_predictions = predict_author(features_tuple, model, scaler, label_encoder)\n",
    "\n",
    "# Display the top 10 predictions\n",
    "for student, probability in author_predictions:\n",
    "    print(f\"{student} has a {probability * 100:.2f}% chance of being the author\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "student_33 has a 16.73% chance of being the author\n",
      "student_30 has a 15.18% chance of being the author\n",
      "student_16 has a 14.27% chance of being the author\n",
      "student_18 has a 8.29% chance of being the author\n",
      "student_35 has a 7.56% chance of being the author\n",
      "student_25 has a 6.28% chance of being the author\n",
      "student_13 has a 4.56% chance of being the author\n",
      "student_5 has a 3.67% chance of being the author\n",
      "student_34 has a 3.66% chance of being the author\n",
      "student_43 has a 2.31% chance of being the author\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preprocessed_image = preprocess_image('student_33.png')\n",
    "features_tuple = extract_features(preprocessed_image)\n",
    "\n",
    "\n",
    "# Predict the author based on the features\n",
    "author_predictions = predict_author(features_tuple, model, scaler, label_encoder)\n",
    "\n",
    "# Display the top 10 predictions\n",
    "for student, probability in author_predictions:\n",
    "    print(f\"{student} has a {probability * 100:.2f}% chance of being the author\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "student_35 has a 50.13% chance of being the author\n",
      "student_25 has a 14.09% chance of being the author\n",
      "student_33 has a 13.65% chance of being the author\n",
      "student_13 has a 10.69% chance of being the author\n",
      "student_18 has a 7.31% chance of being the author\n",
      "student_27 has a 1.04% chance of being the author\n",
      "student_16 has a 0.76% chance of being the author\n",
      "student_4 has a 0.67% chance of being the author\n",
      "student_38 has a 0.41% chance of being the author\n",
      "student_42 has a 0.35% chance of being the author\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preprocessed_image = preprocess_image('student_35.png')\n",
    "features_tuple = extract_features(preprocessed_image)\n",
    "\n",
    "\n",
    "# Predict the author based on the features\n",
    "author_predictions = predict_author(features_tuple, model, scaler, label_encoder)\n",
    "\n",
    "# Display the top 10 predictions\n",
    "for student, probability in author_predictions:\n",
    "    print(f\"{student} has a {probability * 100:.2f}% chance of being the author\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
